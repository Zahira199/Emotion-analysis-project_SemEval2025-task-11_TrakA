{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_combined=pd.read_csv('/content/train.csv')\n",
        "df_combined_dev=pd.read_csv('/content/dev.csv')\n",
        "df_combined_test=pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "KqZb9QIuDv5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hix75bvxDeC9",
        "outputId": "deeebcee-9ceb-4466-b3dd-6e0002b523fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Validation (Dev) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.50      0.56      0.53        79\n",
            "     disgust       0.31      0.37      0.34        38\n",
            "        fear       0.39      0.57      0.46        46\n",
            "         joy       0.38      0.49      0.43        47\n",
            "     sadness       0.48      0.58      0.53        79\n",
            "    surprise       0.38      0.49      0.42        68\n",
            "\n",
            "   micro avg       0.42      0.52      0.46       357\n",
            "   macro avg       0.41      0.51      0.45       357\n",
            "weighted avg       0.42      0.52      0.47       357\n",
            " samples avg       0.31      0.38      0.32       357\n",
            "\n",
            "\n",
            "=== Test Final ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.46      0.53      0.49       486\n",
            "     disgust       0.27      0.48      0.34       241\n",
            "        fear       0.36      0.59      0.45       279\n",
            "         joy       0.39      0.33      0.36       312\n",
            "     sadness       0.54      0.71      0.61       533\n",
            "    surprise       0.39      0.56      0.46       434\n",
            "\n",
            "   micro avg       0.42      0.55      0.47      2285\n",
            "   macro avg       0.40      0.53      0.45      2285\n",
            "weighted avg       0.42      0.55      0.48      2285\n",
            " samples avg       0.32      0.41      0.34      2285\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier #permet de gérer des problèmes de classification multiclasse avec des classifieurs binaires.\n",
        "from sklearn.metrics import classification_report #générer un rapport d’évaluation\n",
        "from sklearn.pipeline import Pipeline # permet de chaîner plusieurs étapes de traitement\n",
        "\n",
        "# === 1. Charger les DataFrames ===\n",
        "# Assure-toi que df_combined_train, df_combined_dev et df_combined_test sont déjà disponibles\n",
        "\n",
        "# === 2. Définir les colonnes des labels ===\n",
        "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
        "\n",
        "# === 3. Séparer les features et les labels ===\n",
        "X_train = df_combined['clean_text'].fillna('')\n",
        "y_train = df_combined[emotion_labels]\n",
        "\n",
        "X_dev = df_combined_dev['clean_text'].fillna('')\n",
        "y_dev = df_combined_dev[emotion_labels]\n",
        "\n",
        "X_test = df_combined_test['clean_text'].fillna('')\n",
        "y_test = df_combined_test[emotion_labels]\n",
        "\n",
        "\n",
        "# === 4. Créer le pipeline TF-IDF + Classifieur ===\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        tokenizer=lambda x: x.split(),  # suppose que le texte est déjà tokenisé\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=2, # ignore les mots rares\n",
        "        max_df=0.9 # ignore les mots trop fréquents\n",
        "    )),\n",
        "    ('clf', OneVsRestClassifier(\n",
        "        LogisticRegression(\n",
        "            class_weight='balanced',\n",
        "            max_iter=1000,\n",
        "            solver='liblinear'\n",
        "        )\n",
        "    ))\n",
        "])\n",
        "\n",
        "# === 5. Entraîner le modèle ===\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# === 6. Évaluer sur Dev ===\n",
        "print(\"=== Validation (Dev) ===\")\n",
        "y_pred_dev = pipeline.predict(X_dev)\n",
        "print(classification_report(y_dev, y_pred_dev, target_names=emotion_labels, zero_division=0))\n",
        "\n",
        "# === 7. Évaluer sur Test ===\n",
        "print(\"\\n=== Test Final ===\")\n",
        "y_pred_test = pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_test, target_names=emotion_labels, zero_division=0))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "# Fonction tokenizer globale (picklable)\n",
        "def simple_tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "# === Charger les DataFrames ===\n",
        "# df_combined, df_combined_dev, df_combined_test déjà chargés\n",
        "\n",
        "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
        "\n",
        "X_train = df_combined['clean_text'].fillna('')\n",
        "y_train = df_combined[emotion_labels]\n",
        "\n",
        "X_dev = df_combined_dev['clean_text'].fillna('')\n",
        "y_dev = df_combined_dev[emotion_labels]\n",
        "\n",
        "X_test = df_combined_test['clean_text'].fillna('')\n",
        "y_test = df_combined_test[emotion_labels]\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        #tokenizer=simple_tokenizer,\n",
        "        ngram_range=(1, 2),\n",
        "        min_df=2,\n",
        "        max_df=0.9\n",
        "    )),\n",
        "    ('clf', OneVsRestClassifier(\n",
        "        LogisticRegression(\n",
        "            class_weight='balanced',\n",
        "            max_iter=1000,\n",
        "            solver='liblinear'\n",
        "        )\n",
        "    ))\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Sauvegarde du modèle\n",
        "joblib.dump(pipeline, 'mon_modele_emotions.joblib')\n",
        "print(\"Modèle sauvegardé !\")\n",
        "\n",
        "# Évaluation\n",
        "print(\"=== Validation (Dev) ===\")\n",
        "y_pred_dev = pipeline.predict(X_dev)\n",
        "print(classification_report(y_dev, y_pred_dev, target_names=emotion_labels, zero_division=0))\n",
        "\n",
        "print(\"\\n=== Test Final ===\")\n",
        "y_pred_test = pipeline.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_test, target_names=emotion_labels, zero_division=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0mA_s88ENcR",
        "outputId": "c2c8ee1c-3f1d-4c5f-c527-765b0ea1b919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modèle sauvegardé !\n",
            "=== Validation (Dev) ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.50      0.56      0.53        79\n",
            "     disgust       0.31      0.37      0.34        38\n",
            "        fear       0.39      0.57      0.46        46\n",
            "         joy       0.38      0.49      0.43        47\n",
            "     sadness       0.48      0.58      0.53        79\n",
            "    surprise       0.38      0.49      0.42        68\n",
            "\n",
            "   micro avg       0.42      0.52      0.46       357\n",
            "   macro avg       0.41      0.51      0.45       357\n",
            "weighted avg       0.42      0.52      0.47       357\n",
            " samples avg       0.31      0.38      0.32       357\n",
            "\n",
            "\n",
            "=== Test Final ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       anger       0.46      0.53      0.49       486\n",
            "     disgust       0.27      0.48      0.34       241\n",
            "        fear       0.36      0.59      0.45       279\n",
            "         joy       0.39      0.33      0.36       312\n",
            "     sadness       0.54      0.71      0.61       533\n",
            "    surprise       0.39      0.56      0.46       434\n",
            "\n",
            "   micro avg       0.42      0.55      0.47      2285\n",
            "   macro avg       0.40      0.53      0.45      2285\n",
            "weighted avg       0.42      0.55      0.48      2285\n",
            " samples avg       0.32      0.41      0.34      2285\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Recharger le modèle sauvegardé\n",
        "pipeline = joblib.load('mon_modele_emotions.joblib')\n",
        "\n",
        "# Exemple de phrases en darija marocaine\n",
        "phrases_darija = [\n",
        "    \"أنا مفرح بزاف اليوم\",\n",
        "    \"هادشي عجيب و خايف\",\n",
        "    \"كنحس بغضب كبير\",\n",
        "    \"مازال كنحس بحزن\",\n",
        "]\n",
        "\n",
        "\n",
        "# Prédiction (multi-label)\n",
        "preds = pipeline.predict(phrases_darija)\n",
        "\n",
        "# Affichage simple des résultats\n",
        "for phrase, pred in zip(phrases_darija, preds):\n",
        "    emotions = [label for label, present in zip(['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise'], pred) if present]\n",
        "    print(f\"Phrase : {phrase}\")\n",
        "    print(f\"Emotions prédites : {emotions}\")\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "id": "Vwyw29yPF-MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmyM9t5xHZuV",
        "outputId": "033cb5b9-d4df-47ca-e327-be95aebb08d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.32.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.6.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.10.2 (from gradio)\n",
            "  Downloading gradio_client-1.10.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.47.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.2->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.32.0-py3-none-any.whl (54.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.10.2-py3-none-any.whl (323 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.3/323.3 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.12-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.6.0-py3-none-any.whl (5.5 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 fastapi-0.115.12 ffmpy-0.6.0 gradio-5.32.0 gradio-client-1.10.2 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.12 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import joblib\n",
        "\n",
        "# Charger le modèle sauvegardé\n",
        "pipeline = joblib.load('mon_modele_emotions.joblib')\n",
        "\n",
        "# Liste des émotions\n",
        "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']\n",
        "\n",
        "# Fonction de prédiction qui retourne seulement les émotions détectées\n",
        "def predict_emotions(text):\n",
        "    preds = pipeline.predict([text])[0]  # tableau [0, 1, 1, 0, ...]\n",
        "    emotions_detected = [label for label, value in zip(emotion_labels, preds) if value == 1]\n",
        "\n",
        "    if emotions_detected:\n",
        "        return \" / \".join(emotions_detected)\n",
        "    else:\n",
        "        return \"Aucune émotion détectée.\"\n",
        "\n",
        "# Interface Gradio\n",
        "iface = gr.Interface(\n",
        "    fn=predict_emotions,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"اكتب جملة باللهجة المغربية...\"),\n",
        "    outputs=gr.Textbox(label=\"Émotions détectées\"),\n",
        "    title=\"Détecteur d'émotions - Darija\",\n",
        "    description=\"Entrez une phrase en darija marocaine pour détecter les émotions présentes.\"\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "5BUVQhCgHkgY",
        "outputId": "6695a72b-96d1-4f57-dd14-3f2c0503d546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://cef7725a52fb126c36.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cef7725a52fb126c36.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CSQvAsBbJMs1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}